
# ğŸ§  Real-Time Concentration Tracker using MediaPipe & OpenCV

This project implements a **real-time facial behavior monitoring system** that evaluates and visualizes a user's **concentration level** using facial landmarks, eye movements, gaze direction, and head posture. Built using **Python**, **MediaPipe**, and **OpenCV**, it provides an interactive interface to help track attention and distraction over time.

---

## ğŸ’¡ Overview

The Concentration Tracker uses **MediaPipe FaceMesh** to extract facial landmarks and infer important attention-related cues such as:

- **Eye Aspect Ratio (EAR)** for blink detection
- **Iris movement** for gaze tracking
- **Nose position** for head pose estimation
- **A combined heuristic model** to compute concentration level

By aggregating these features, the system provides a smooth, real-time score (0â€“100%) representing the user's concentration level. It also tracks distraction frequency and alerts when attention drops consistently.

---

## ğŸ¯ Key Features

- ğŸ” **Facial Landmark Detection:** Accurate landmark tracking using MediaPipe's FaceMesh with 468 facial points.
- ğŸ‘ï¸ **Blink Detection:** Calculates Eye Aspect Ratio (EAR) to detect eye closure and blinks.
- ğŸ‘€ **Gaze Estimation:** Uses iris coordinates to determine if the user is looking ahead or away.
- ğŸ§­ **Head Pose Scoring:** Detects head orientation based on nose deviation from screen center.
- ğŸ“Š **Concentration Scoring:** Computes a real-time weighted concentration score based on gaze, head pose, and blink activity.
- ğŸ“‰ **Distraction Monitoring:** Increments a distraction counter when attention score drops below threshold.
- âš™ï¸ **Live Visualization:** Includes a concentration bar, attention status indicator, and distraction alerts overlayed on the video feed.
- ğŸ“ˆ **Smooth Score Tracking:** Uses a history queue to average out the concentration score and reduce jitter.
- ğŸ§ª **Modular Design:** Each component (eye detection, head pose, gaze, scoring) is independently manageable for easy tuning and experimentation.

---

## ğŸ§  How Concentration is Measured

The system calculates a **concentration score (0â€“100%)** using the following weighted heuristic:

```
Concentration Score = 0.4 Ã— Gaze Score + 0.4 Ã— Head Pose Score + 0.2 Ã— (1 - Blink Penalty)
```

- **Gaze Score:** 1 if the user is looking forward, else 0
- **Head Pose Score:** 1 if the head is oriented toward the camera, else 0
- **Blink Penalty:** 1 if a blink is detected, else 0

A **score above 40%** indicates attentiveness, while scores below that contribute to the **distraction counter**.

---

## ğŸ§° Requirements

Ensure you have Python 3.7 or higher. Install the following libraries:

```bash
pip install opencv-python mediapipe numpy
```

---

## ğŸš€ Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/concentration-tracker.git
   cd concentration-tracker
   ```

2. Run the application:
   ```bash
   python main.py
   ```

3. The webcam window will launch with live feedback.

4. Press `q` to exit the window.

---

## ğŸ§ª Applications

This system can be adapted or expanded for:

- ğŸ“š **Online Education:** Monitor student attentiveness during virtual classes
- ğŸ‘¨â€ğŸ’» **Workplace Productivity:** Track screen focus during remote work
- ğŸ§‘â€ğŸ« **Tutoring & Assessments:** Detect off-screen distractions
- ğŸ§  **Cognitive Research:** Analyze user behavior and focus patterns
- ğŸ‘ï¸ **Human-Computer Interaction:** Real-time feedback for adaptive systems

---

## ğŸ§‘â€ğŸ’» Technologies Used

- **Python** â€“ Core programming language
- **MediaPipe** â€“ FaceMesh for landmark extraction
- **OpenCV** â€“ Image processing and rendering
- **NumPy** â€“ Numerical computation and geometry operations

---

## ğŸ“Œ Notes

- Gaze and head-pose estimation are heuristic and may vary slightly with lighting and camera angle.
- The model does not perform face recognition â€” it only detects and tracks general facial behaviors.
- This is an on-device solution â€” no internet or cloud processing is required.

---

## ğŸ¤ Contributions

Contributions and suggestions are welcome! Whether it's improving gaze tracking, adding logging/analytics, or adapting it for mobile/web â€” feel free to fork the project and raise a pull request.

---


---

## ğŸ™ Acknowledgments

- [MediaPipe by Google](https://google.github.io/mediapipe/) for enabling high-performance face tracking.
- The open-source community for the foundational tools used in this project.

---

> âœ¨ â€œThis system aims not just to track where your eyes go â€” but whether your mind stays.â€
